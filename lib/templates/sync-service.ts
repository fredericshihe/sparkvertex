// ============================================
// SparkVertex Cloud Sync Service Template
// ============================================

export const SYNC_SERVICE_TEMPLATE = `
// ============================================
// SparkVertex Cloud Sync Service
// ä»äº‘ç«¯ä¿¡ç®±åŒæ­¥åŠ å¯†æ•°æ®åˆ°æœ¬åœ°
// ============================================

class SparkSync {
  constructor(appId, privateKey) {
    this.appId = appId;
    this.privateKey = privateKey;
    this.apiBase = '{{API_BASE}}';
    this.syncInterval = null;
    this.isSyncing = false;
    this.lastSync = null;
    this.listeners = new Set();
  }
  
  // æ·»åŠ åŒæ­¥äº‹ä»¶ç›‘å¬
  onSync(callback) {
    this.listeners.add(callback);
    return () => this.listeners.delete(callback);
  }
  
  _emit(event, data) {
    this.listeners.forEach(cb => cb(event, data));
    window.dispatchEvent(new CustomEvent(\`spark:sync:\${event}\`, { detail: data }));
  }
  
  async start(intervalMs = 30000) {
    // ç«‹å³æ‰§è¡Œä¸€æ¬¡
    await this.sync();
    
    // å®šæ—¶æ‰§è¡Œ
    this.syncInterval = setInterval(() => this.sync(), intervalMs);
    console.log(\`ğŸ”„ Sync started (every \${intervalMs / 1000}s)\`);
  }
  
  stop() {
    if (this.syncInterval) {
      clearInterval(this.syncInterval);
      this.syncInterval = null;
      console.log('â¹ï¸ Sync stopped');
    }
  }
  
  async sync() {
    if (this.isSyncing) {
      console.log('â³ Sync already in progress');
      return { skipped: true };
    }
    
    this.isSyncing = true;
    this._emit('start', { timestamp: new Date() });
    
    try {
      // 1. ä»äº‘ç«¯æ‹‰å–æ–°æ¶ˆæ¯
      const res = await fetch(
        \`\${this.apiBase}/api/mailbox/sync?app_id=\${this.appId}\`,
        { credentials: 'include' }
      );
      
      if (!res.ok) {
        throw new Error(\`Sync failed: \${res.status}\`);
      }
      
      const { messages, total_pending } = await res.json();
      
      if (messages.length === 0) {
        console.log('ğŸ“­ No new messages');
        this._emit('complete', { processed: 0, pending: total_pending });
        return { processed: 0, pending: total_pending };
      }
      
      console.log(\`ğŸ“¬ Received \${messages.length} new messages (\${total_pending} total pending)\`);
      
      // 2. å¤„ç†æ¯æ¡æ¶ˆæ¯
      const processedIds = [];
      const errors = [];
      
      for (const msg of messages) {
        try {
          // è§£å¯†
          const decrypted = await this.decrypt(msg.encrypted_payload);
          
          // å†™å…¥æœ¬åœ°æ•°æ®åº“
          await this.saveToLocal(decrypted, msg.metadata);
          
          processedIds.push(msg.id);
          
        } catch (e) {
          console.error('Message processing failed:', e);
          errors.push({ id: msg.id, error: e.message });
        }
      }
      
      // 3. æ‰¹é‡ç¡®è®¤æ”¶åˆ°
      if (processedIds.length > 0) {
        await fetch(\`\${this.apiBase}/api/mailbox/ack\`, {
          method: 'POST',
          headers: { 'Content-Type': 'application/json' },
          credentials: 'include',
          body: JSON.stringify({
            message_ids: processedIds,
            app_id: this.appId
          })
        });
      }
      
      // 4. è§¦å‘ç¡¬ç›˜å¤‡ä»½
      if (window.sparkBackup && processedIds.length > 0) {
        await window.sparkBackup.save().catch(console.error);
      }
      
      this.lastSync = new Date();
      
      const result = {
        processed: processedIds.length,
        errors: errors.length,
        pending: total_pending - processedIds.length
      };
      
      this._emit('complete', result);
      console.log(\`âœ… Sync complete: \${processedIds.length} processed\`);
      
      return result;
      
    } catch (e) {
      console.error('Sync error:', e);
      this._emit('error', { error: e.message });
      throw e;
    } finally {
      this.isSyncing = false;
    }
  }
  
  async decrypt(encryptedPayload) {
    try {
      const { iv, data } = JSON.parse(atob(encryptedPayload));
      
      const key = await crypto.subtle.importKey(
        'jwk',
        this.privateKey,
        { name: 'RSA-OAEP', hash: 'SHA-256' },
        false,
        ['decrypt']
      );
      
      const decrypted = await crypto.subtle.decrypt(
        { name: 'RSA-OAEP' },
        key,
        new Uint8Array(data)
      );
      
      return JSON.parse(new TextDecoder().decode(decrypted));
    } catch (e) {
      console.error('Decryption failed:', e);
      throw new Error('Failed to decrypt message');
    }
  }
  
  // ä¿å­˜åˆ°æœ¬åœ°æ•°æ®åº“ - éœ€è¦æ ¹æ®å…·ä½“ Schema å®ç°
  async saveToLocal(data, metadata) {
    if (!window.sparkDB || !window.sparkDB.ready) {
      throw new Error('Local database not ready');
    }
    
    // æ£€æŸ¥æ•°æ®ç±»å‹å¹¶è·¯ç”±åˆ°ç›¸åº”å¤„ç†å™¨
    const type = data._type || data.type || 'submission';
    
    switch (type) {
      case 'submission':
      case 'form':
        return this.saveSubmission(data, metadata);
      case 'encrypted_file':
        return this.saveFileReference(data, metadata);
      default:
        return this.saveGeneric(data, metadata);
    }
  }
  
  async saveSubmission(data, metadata) {
    // é»˜è®¤å®ç° - ä¿å­˜åˆ° submissions è¡¨
    const { _type, ...fields } = data;
    
    const columns = Object.keys(fields);
    const values = Object.values(fields);
    const placeholders = columns.map((_, i) => \`$\${i + 1}\`);
    
    // æ·»åŠ å…ƒæ•°æ®
    columns.push('_metadata', '_synced_at');
    values.push(JSON.stringify(metadata), new Date().toISOString());
    placeholders.push(\`$\${columns.length - 1}\`, \`$\${columns.length}\`);
    
    await window.sparkDB.query(\`
      INSERT INTO submissions (\${columns.join(', ')})
      VALUES (\${placeholders.join(', ')})
    \`, values);
  }
  
  async saveFileReference(data, metadata) {
    // ä¿å­˜åŠ å¯†æ–‡ä»¶å¼•ç”¨
    await window.sparkDB.query(\`
      INSERT INTO _spark_files (
        path, encrypted_key, iv, original_name, original_size, mime_type, 
        _metadata, _synced_at
      ) VALUES ($1, $2, $3, $4, $5, $6, $7, $8)
    \`, [
      data.path,
      data.key,
      JSON.stringify(data.iv),
      data.original_name,
      data.original_size,
      data.mime_type,
      JSON.stringify(metadata),
      new Date().toISOString()
    ]);
  }
  
  async saveGeneric(data, metadata) {
    // ä¿å­˜åˆ°é€šç”¨è¡¨
    await window.sparkDB.query(\`
      INSERT INTO _spark_inbox (data, metadata, synced_at)
      VALUES ($1, $2, $3)
    \`, [
      JSON.stringify(data),
      JSON.stringify(metadata),
      new Date().toISOString()
    ]);
  }
  
  getStatus() {
    return {
      isRunning: !!this.syncInterval,
      isSyncing: this.isSyncing,
      lastSync: this.lastSync
    };
  }
}

// å…¨å±€å®ä¾‹å ä½ç¬¦
window.sparkSync = null;
`;

// ç”Ÿæˆå¸¦æœ‰å…·ä½“é…ç½®çš„æ¨¡æ¿
export function generateSyncServiceCode(appId: string, apiBase: string): string {
  return SYNC_SERVICE_TEMPLATE
    .replace(/\{\{APP_ID\}\}/g, appId)
    .replace(/\{\{API_BASE\}\}/g, apiBase);
}
